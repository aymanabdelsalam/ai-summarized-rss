<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>My AI Top News Summary (Ranked by Topic Repetition)</title><link>https://aymanabdelsalam.github.io/ai-summarized-rss/</link><description>The most prominent news story (ranked by repetition across sources and recency from last 12hrs), with detailed multi-paragraph AI summary.</description><language>en-us</language><lastBuildDate>Wed, 29 Oct 2025 16:19:34 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Character.AI bans users under 18 after being sued over child’s suicide</title><link>https://www.theguardian.com/technology/2025/oct/29/character-ai-suicide-children-ban</link><description>الشركات اللي بتعمل برامج محادثة بالذكاء الاصطناعي (AI) زي Character.AI، بدأت تاخد خطوات لحماية الأطفال والمراهقين. ده جه بعد ضغط كبير ومخاوف جدية عن تأثير البرامج دي على الصحة النفسية للشباب، وكمان بعد دعاوى قضائية اتعملت ضدها.

بشكل رسمي، شركة Character.AI هتبدأ من أواخر شهر نوفمبر تمنع أي حد عمره أقل من 18 سنة إنه يتكلم مع البرامج بتاعتها. ده هيحصل بعد ما الشركة واجهت أسئلة كتير وصعبة عن إزاي البرامج دي ممكن تأثر على تفكير وصحة المراهقين، وكمان فيه قانون جديد بيقترح منع الأطفال من استخدام البرامج دي.

الشركة نفسها قالت إنها بتعمل التغييرات دي بسبب التطورات السريعة في مجال الذكاء الاصطناعي وتعامل المراهقين معاه. ده جه كمان بعد تقارير إخبارية بتثير تساؤلات، ومنظمات رقابية سألت عن المحتوى اللي ممكن المراهقين يقابلوه في محادثاتهم مع الذكاء الاصطناعي، وإزاي المحادثات دي ممكن تأثر عليهم حتى لو فيه ضوابط للمحتوى.

الموضوع ده مش جديد على الشركات دي، ففي السنة اللي فاتت، عيلة شاب عنده 14 سنة رفعت قضية ضد Character.AI لأنه انتحر بعد ما ارتبط عاطفياً بشخصية عملها على البرنامج. العيلة دي اتهمت الشركة إن التكنولوجيا بتاعتهم "خطيرة وغير مجربة". من وقتها، عائلات تانية رفعت قضايا مشابهة. كمان، في بداية الشهر ده، مركز قانون وسائل التواصل الاجتماعي رفع 3 قضايا جديدة ضد الشركة باسم أطفال ماتوا بالانتحار أو اتعلقوا بالروبوتات دي بشكل كبير.

كجزء من التغييرات دي، اللي هتبدأ يوم 25 نوفمبر، Character.AI هتقدم نظام "تأكيد العمر" عشان تتأكد إن المستخدمين بياخدوا التجربة المناسبة لعمرهم. الشركة أكدت إنهم مش بيعملوا الخطوة دي بسهولة، لكن شايفين إنها الخطوة الصح عشان الإجابة على الأسئلة المطروحة حول تفاعل المراهقين مع التكنولوجيا الجديدة دي.

مش بس Character.AI اللي بتواجه ضغوط، شركات تانية كمان بتتعرض لانتقادات بسبب تأثير الروبوتات بتاعتها على الصحة النفسية، خصوصاً عند المستخدمين الصغيرين. عيلة شاب عنده 16 سنة رفعت قضية ضد OpenAI السنة دي، واتهمتهم إنهم بيركزوا أكتر على زيادة تفاعل المستخدمين مع ChatGPT على حساب سلامتهم. OpenAI ردت بحط قوانين أمان جديدة للمستخدمين المراهقين. وكمان، OpenAI كشفت الأسبوع ده إن أكتر من مليون شخص في الأسبوع بيظهر عليهم نوايا انتحارية وهم بيتكلموا مع ChatGPT، ومئات الآلاف بيظهر عليهم علامات ذهانية.

في أمريكا، فيه جهود كتير على مستوى الولايات والمستوى الفيدرالي عشان نحط ضوابط للتكنولوجيا دي. كاليفورنيا كانت أول ولاية تمرر قانون الذكاء الاصطناعي اللي بيحط إرشادات سلامة للقصر في أكتوبر 2025، واللي هيدخل حيز التنفيذ في بداية 2026. القانون ده بيمنع المحتوى الجنسي للقصر وبيطلب يبعتوا تذكيرات للأطفال كل 3 ساعات إنهم بيتكلموا مع ذكاء اصطناعي. advocacy advocates شايفين إن القانون ده مش كفاية.

على المستوى الوطني، سناتورين في أمريكا أعلنوا عن مشروع قانون الثلاثاء اللي هيمنع القصر من استخدام برامج الذكاء الاصطناعي التفاعلية، وهيطلب من الشركات تعمل عملية تحقق من العمر. السناتور جوش هاولي صرح إن أكتر من 70% من الأطفال الأمريكيين بيستخدموا منتجات الذكاء الاصطناعي دي، وإن الروبوتات بتعمل علاقات مع الأطفال باستخدام تعاطف مزيف وبتشجع على الانتحار، وإن الكونجرس عنده واجب أخلاقي يسن قوانين واضحة لمنع المزيد من الضرر من التكنولوجيا الجديدة دي.

Source for summary: The Gardian</description><guid isPermaLink="true">https://www.theguardian.com/technology/2025/oct/29/character-ai-suicide-children-ban</guid><pubDate>Wed, 29 Oct 2025 16:07:25 GMT</pubDate></item></channel></rss>